{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpXF9ymZesWh"
      },
      "source": [
        "# Tworzenie potoków przetwarzania danych\n",
        "\n",
        "Na dzisiejszych zajęciach jak również na zajęciach z genomiki mieliśmy okazję zapoznać się z programami służącymi do obróbki danych pochodzących z sekwencjonowania wysokoprzepustowego. Jest to proces wieloetapowy, gdzie wykorzystywane są różne narzedzia a operacje wykonywane są na różnych rodzajach plików wejściowych generując nowego rodzaju dane. Biorąc pod uwage mnogość etapów analizy, jak również konieczność analizy wielu plików na raz ręczne wykonywanie po koleji kolejnych etapów analizy staje się niepraktyczne i nieefektywne. W odpowiedzi na te wyzwania stworzono programy do zarządzania przepływem danych, tzw. języki definicji przepływu pracy (ang. Workflow languages).\n",
        "\n",
        "## Najpopularniejsze rodzaje języków definicji przepływu pracy\n",
        "Języki definicji przepływu pracy zapewniają ustrukturyzowane ramy do opisywania i organizowania serii zadań wymaganych do analizy danych. Istnieje wiele języków definiowania przepływów pracy, używanych do pisania potoków obliczeniowych.\n",
        "\n",
        "### Nextflow\n",
        "<div>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e1/Logo_Nextflow_%28new%29.png\"\n",
        "width=400/>\n",
        "</div>\n",
        "\n",
        "[Strona WWW](https://www.nextflow.io/) \\\n",
        "Potok Nextflow składa się z jednego lub więcej modułów lub procesów. Nextflow umożliwia wykonanie skryptu, który może być napisany w dowolnym popularnym języku skryptowym, w tym Bash, Python i R. Nextflow jest wspierany przez dużą społeczność programistów i bioinformatyków. Istnieje również [nf-core](https://nf-co.re/pipelines/), duża biblioteka potoków bioinformatycznych open-source napisanych w Nextflow.\n",
        "* Wykorzystuje język Groovy.\n",
        "* Silna integracja ze środowiskami kontenerowymi (Docker, Singularity).\n",
        "* Wysoka elastyczność w obsłudze plików, wykonywaniu zadań i zrównoleglaniu.\n",
        "* Kompatybilność ze środowiskami chmurowymi i klastrowymi (AWS, Google Cloud, Slurm itp.).\n",
        "\n",
        "Najpopularniejszy pipeline do analizy danych germinalnych i somatycznych z sekwencjonowania NGS to [nf-core/sarek](https://nf-co.re/sarek/3.4.4/). Potok ten jest podzielony na kilka składowych częsci:\n",
        "* [workflows/sarek/main.nf](https://github.com/nf-core/sarek/blob/3.4.4/workflows/sarek/main.nf) - Główny plik \"workflow\" określający poszczególne kroki takie jak przygotowanie danych, uliniowienie czy wykrywanie wariantów z użyciem zaimportowanych subworkflow's oraz modułów. Poniżej przykład importu informacji ze skryptu do uliniowienia plików fastq:\n",
        "* [subworkflows/local/fastq_align_bwamem_mem2_dragmap_sentieon/main.nf](https://github.com/nf-core/sarek/blob/3.4.4/subworkflows/local/fastq_align_bwamem_mem2_dragmap_sentieon/main.nf) - Pośrednie pliki \"subworkflow\" definiujące kroki w poszczególnych pomniejszych etapach, np. jak uliniowienie w pliku\n",
        "* [modules/bwa/mem/main.nf](https://github.com/nf-core/sarek/blob/3.4.4/modules/nf-core/bwa/mem/main.nf) - pliki \"modules\" definiujące pliki wejściowe i wyjściowe dla poszczególnych programów oraz ich uruchomienie\n",
        "\n",
        "### Common Workflow Language\n",
        "<div>\n",
        "<img src=\"https://repository-images.githubusercontent.com/24454775/a0f7b480-04d7-11eb-9513-240001f2f87a\"\n",
        "width=400/>\n",
        "</div>\n",
        "\n",
        "[Strona WWW](https://www.commonwl.org/user_guide/) \\\n",
        "[Narzedzia do uruchamiania skrytpów CWL](https://www.commonwl.org/implementations/) \\\n",
        "Common Workflow Language (lub CWL) to język służący do definiowania przepływów pracy w sposób wieloplatformowy. CWL zapewnia prosty i dobrze zdefiniowany format do automatyzacji tych analiz poprzez określenie ich etapów i połączeń za pomocą czytelnych dokumentów CWL. Ekosystem CWL powiększył się o narzędzia do wizualizacji przepływu pracy, graficzne edytory przepływu pracy, biblioteki do programowej interakcji z CWL oraz narzędzia konwertujące do i z CWL oraz innych formatów przepływu pracy.\n",
        "* Wykorzystuje YAML/JSON do definiowania przepływów pracy, kładąc nacisk na prostotę i czytelność.\n",
        "* Oddziela definicje narzędzi i przepływy pracy, aby umożliwić ponowne wykorzystanie komponentów.\n",
        "* Silna społeczność i skupienie na standardach, często postrzegane jako „klej” do łączenia narzędzi bioinformatycznych w różnych systemach.\n",
        "* Zaprojektowany z myślą o szerokiej kompatybilności, umożliwiając uruchomienie tego samego przepływu pracy na różnych platformach przy minimalnych zmianach.\n",
        "\n",
        "\n",
        "### Workflow Description Language\n",
        "<div>\n",
        "<img src=\"https://vsmalladi.github.io/openwdl.github.io//media/logo-preview.png\"\n",
        "width=400/>\n",
        "</div>\n",
        "\n",
        "[Strona WWW](https://openwdl.org/getting-started/) \\\n",
        "[Narzedzia do uruchamiania skrytpów WDL](https://github.com/openwdl/wdl/tree/wdl-1.2?tab=readme-ov-file#execution-engines-and-platforms) \\\n",
        "[Repozytoria potoków w WDL](https://github.com/openwdl/wdl/tree/wdl-1.2?tab=readme-ov-file#published-workflows) \\\n",
        "Workflow Description Language (WDL) to deklaratywny język przeznaczony do definiowania przepływów pracy związanych z przetwarzaniem danych w prosty i czytelny sposób. Jest on używany głównie w bioinformatyce, ale jest wystarczająco elastyczny dla różnych zastosować.\n",
        "* Prosta składnia, ułatwiająca czytanie i pisanie skryptów.\n",
        "* Silne wsparcie dla genomiki, zintegrowane z Cromwell (silnik wykonawczy).\n",
        "* Możliwość rozszerzenia na różne środowiska chmurowe i HPC.\n",
        "\n",
        "\n",
        "***\n",
        "# Tworzenie potoków przetwarzania danych z użyciem języka WDL i programu Cromwell\n",
        "\n",
        "### Pobranie programu Cromwell do wykonywania skryptów WDL\n",
        "Program jest dostępny do pobrania ze strony [github projektu](https://github.com/broadinstitute/cromwell). \\\n",
        "[Wstęp do Cromwell](https://cromwell.readthedocs.io/en/latest/tutorials/FiveMinuteIntro/) - Obszerna dokumentacja zawiera m.in. informację o instalacji oraz stworzeniu pierwszego potoku.\n",
        "\n",
        "Na początku należy pobrać plik jar niezbędny do uruchomienia programu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ODHxogS8esWj",
        "outputId": "638d9d86-483f-429f-cd29-37181e8897e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-27 16:39:46--  https://github.com/broadinstitute/cromwell/releases/download/87/cromwell-87.jar\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/34136406/8263b4d6-5db2-4ec9-8ad2-26e57c3e82ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241027%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241027T163947Z&X-Amz-Expires=300&X-Amz-Signature=b9f9077de4fd3cfc94d6481305cbae40944ed7463ec3a832e53a0ba5ea24f915&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcromwell-87.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-10-27 16:39:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/34136406/8263b4d6-5db2-4ec9-8ad2-26e57c3e82ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241027%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241027T163947Z&X-Amz-Expires=300&X-Amz-Signature=b9f9077de4fd3cfc94d6481305cbae40944ed7463ec3a832e53a0ba5ea24f915&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcromwell-87.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253034346 (241M) [application/octet-stream]\n",
            "Saving to: ‘cromwell-87.jar’\n",
            "\n",
            "cromwell-87.jar     100%[===================>] 241.31M  44.0MB/s    in 5.4s    \n",
            "\n",
            "2024-10-27 16:39:52 (45.0 MB/s) - ‘cromwell-87.jar’ saved [253034346/253034346]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://github.com/broadinstitute/cromwell/releases/download/87/cromwell-87.jar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PWPQUl7esWk"
      },
      "source": [
        "W celu przetestowania działania programu należy uruchomić przykładowy skrypt WDL. Cromwell korzysta z Javy w wersji 11, dlatego przed komendą uruchamiania programu specyfikujemy ścieżkę gdzie w systemie (w naszym przypadku system w obrazie Dockera) znajduje się odpowiednia wersja Javy. Skrypt znajduje się katalogu `dags/cromwell-test.wdl`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7RVOHJWGj8U7",
        "outputId": "fc88e379-76e3-4c08-9e36-78ddafdbb715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! java -version"
      ],
      "metadata": {
        "id": "B9j3XK3wiWAc",
        "outputId": "259c9ffd-67f5-4855-a350-2d2682270769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.24\" 2024-07-16\n",
            "OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu322.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu322.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fx3nT_kqesWk",
        "outputId": "c8259267-c445-4cdd-cd0a-659fdae212cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-10-27 15:38:08,47] [info] Running with database db.url = jdbc:hsqldb:mem:1cbb5877-74a9-4328-8764-968a882a436f;shutdown=false;hsqldb.tx=mvcc\n",
            "[2024-10-27 15:38:17,47] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000\n",
            "[2024-10-27 15:38:17,52] [info] [RenameWorkflowOptionsInMetadata] 100%\n",
            "[2024-10-27 15:38:18,77] [info] Running with database db.url = jdbc:hsqldb:mem:8ca29ab6-3ea0-43f6-839f-d36afd12678c;shutdown=false;hsqldb.tx=mvcc\n",
            "[2024-10-27 15:38:20,62] [info] Slf4jLogger started\n",
            "[2024-10-27 15:38:20,99] [info] Workflow heartbeat configuration:\n",
            "{\n",
            "  \"cromwellId\" : \"cromid-ac05623\",\n",
            "  \"heartbeatInterval\" : \"2 minutes\",\n",
            "  \"ttl\" : \"10 minutes\",\n",
            "  \"failureShutdownDuration\" : \"5 minutes\",\n",
            "  \"writeBatchSize\" : 10000,\n",
            "  \"writeThreshold\" : 10000\n",
            "}\n",
            "[2024-10-27 15:38:21,19] [info] Metadata summary refreshing every 1 second.\n",
            "[2024-10-27 15:38:21,19] [info] No metadata archiver defined in config\n",
            "[2024-10-27 15:38:21,20] [info] No metadata deleter defined in config\n",
            "[2024-10-27 15:38:21,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.\n",
            "[2024-10-27 15:38:21,30] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.\n",
            "[2024-10-27 15:38:21,36] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.\n",
            "[2024-10-27 15:38:22,41] [info] JobRestartCheckTokenDispenser - Distribution rate: 50 per 1 seconds.\n",
            "[2024-10-27 15:38:22,55] [info] JobExecutionTokenDispenser - Distribution rate: 20 per 10 seconds.\n",
            "[2024-10-27 15:38:22,73] [info] SingleWorkflowRunnerActor: Version 87\n",
            "[2024-10-27 15:38:22,78] [info] SingleWorkflowRunnerActor: Submitting workflow\n",
            "[2024-10-27 15:38:22,89] [info] Unspecified type (Unspecified version) workflow 1b7acc0d-276c-43ad-89e5-117e8d115fde submitted\n",
            "[2024-10-27 15:38:22,96] [info] SingleWorkflowRunnerActor: Workflow submitted \u001b[38;5;2m1b7acc0d-276c-43ad-89e5-117e8d115fde\u001b[0m\n",
            "[2024-10-27 15:38:22,98] [info] 1 new workflows fetched by cromid-ac05623: 1b7acc0d-276c-43ad-89e5-117e8d115fde\n",
            "[2024-10-27 15:38:23,05] [info] WorkflowManagerActor: Starting workflow \u001b[38;5;2m1b7acc0d-276c-43ad-89e5-117e8d115fde\u001b[0m\n",
            "[2024-10-27 15:38:23,11] [info] WorkflowManagerActor: Successfully started WorkflowActor-1b7acc0d-276c-43ad-89e5-117e8d115fde\n",
            "[2024-10-27 15:38:23,11] [info] Retrieved 1 workflows from the WorkflowStoreActor\n",
            "[2024-10-27 15:38:23,22] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.\n",
            "[2024-10-27 15:38:24,10] [info] MaterializeWorkflowDescriptorActor [\u001b[38;5;2m1b7acc0d\u001b[0m]: Parsing workflow as WDL 1.0\n",
            "[2024-10-27 15:38:25,50] [info] MaterializeWorkflowDescriptorActor [\u001b[38;5;2m1b7acc0d\u001b[0m]: Call-to-Backend assignments: test.TestTask -> Local\n",
            "[2024-10-27 15:38:27,20] [info] WorkflowExecutionActor-1b7acc0d-276c-43ad-89e5-117e8d115fde [\u001b[38;5;2m1b7acc0d\u001b[0m]: Starting test.TestTask\n",
            "[2024-10-27 15:38:27,41] [info] Not triggering log of restart checking token queue status. Effective log interval = None\n",
            "[2024-10-27 15:38:27,58] [info] Not triggering log of execution token queue status. Effective log interval = None\n",
            "[2024-10-27 15:38:32,60] [info] Assigned new job execution tokens to the following groups: 1b7acc0d: 1\n",
            "[2024-10-27 15:38:33,23] [info] BackgroundConfigAsyncJobExecutionActor [\u001b[38;5;2m1b7acc0d\u001b[0mtest.TestTask:NA:1]: \u001b[38;5;5mecho \"hello world\"\u001b[0m\n",
            "[2024-10-27 15:38:33,54] [info] BackgroundConfigAsyncJobExecutionActor [\u001b[38;5;2m1b7acc0d\u001b[0mtest.TestTask:NA:1]: executing: /bin/bash /content/cromwell-executions/test/1b7acc0d-276c-43ad-89e5-117e8d115fde/call-TestTask/execution/script\n",
            "[2024-10-27 15:38:36,33] [info] BackgroundConfigAsyncJobExecutionActor [\u001b[38;5;2m1b7acc0d\u001b[0mtest.TestTask:NA:1]: job id: 7469\n",
            "[2024-10-27 15:38:36,34] [info] BackgroundConfigAsyncJobExecutionActor [\u001b[38;5;2m1b7acc0d\u001b[0mtest.TestTask:NA:1]: Status change from - to Done\n",
            "[2024-10-27 15:38:36,47] [info] WorkflowExecutionActor-1b7acc0d-276c-43ad-89e5-117e8d115fde [\u001b[38;5;2m1b7acc0d\u001b[0m]: Workflow test complete. Final Outputs:\n",
            "{\n",
            "  \"test.TestTask.out\": \"hello world\"\n",
            "}\n",
            "[2024-10-27 15:38:41,36] [info] WorkflowManagerActor: Workflow actor for 1b7acc0d-276c-43ad-89e5-117e8d115fde completed with status 'Succeeded'. The workflow will be removed from the workflow store.\n",
            "[2024-10-27 15:38:42,78] [info] SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.\n",
            "{\n",
            "  \"outputs\": {\n",
            "    \"test.TestTask.out\": \"hello world\"\n",
            "  },\n",
            "  \"id\": \"1b7acc0d-276c-43ad-89e5-117e8d115fde\"\n",
            "}\n",
            "[2024-10-27 15:38:46,38] [info] Workflow polling stopped\n",
            "[2024-10-27 15:38:46,41] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds\n",
            "[2024-10-27 15:38:46,42] [info] Aborting all running workflows.\n",
            "[2024-10-27 15:38:46,44] [info] WorkflowStoreActor stopped\n",
            "[2024-10-27 15:38:46,44] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds\n",
            "[2024-10-27 15:38:46,45] [info] 0 workflows released by cromid-ac05623\n",
            "[2024-10-27 15:38:46,46] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds\n",
            "[2024-10-27 15:38:46,46] [info] JobExecutionTokenDispenser stopped\n",
            "[2024-10-27 15:38:46,46] [info] WorkflowLogCopyRouter stopped\n",
            "[2024-10-27 15:38:46,46] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds\n",
            "[2024-10-27 15:38:46,47] [info] WorkflowManagerActor stopped\n",
            "[2024-10-27 15:38:46,47] [info] WorkflowManagerActor: All workflows finished\n",
            "[2024-10-27 15:38:46,84] [info] Connection pools shut down\n",
            "[2024-10-27 15:38:46,84] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds\n",
            "[2024-10-27 15:38:46,84] [info] Shutting down JobStoreActor - Timeout = 1800 seconds\n",
            "[2024-10-27 15:38:46,84] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds\n",
            "[2024-10-27 15:38:46,84] [info] SubWorkflowStoreActor stopped\n",
            "[2024-10-27 15:38:46,84] [info] JobStoreActor stopped\n",
            "[2024-10-27 15:38:46,84] [info] CallCacheWriteActor Shutting down: 0 queued messages to process\n",
            "[2024-10-27 15:38:46,84] [info] CallCacheWriteActor stopped\n",
            "[2024-10-27 15:38:46,84] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds\n",
            "[2024-10-27 15:38:46,84] [info] Shutting down DockerHashActor - Timeout = 1800 seconds\n",
            "[2024-10-27 15:38:46,85] [info] Shutting down IoProxy - Timeout = 1800 seconds\n",
            "[2024-10-27 15:38:46,85] [info] IoProxy stopped\n",
            "[2024-10-27 15:38:46,85] [info] KvWriteActor Shutting down: 0 queued messages to process\n",
            "[2024-10-27 15:38:46,85] [info] WriteMetadataActor Shutting down: 0 queued messages to process\n",
            "[2024-10-27 15:38:46,88] [info] DockerHashActor stopped\n",
            "[2024-10-27 15:38:46,89] [info] ServiceRegistryActor stopped\n",
            "[2024-10-27 15:38:46,94] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false\n",
            "[2024-10-27 15:38:46,94] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false\n",
            "[2024-10-27 15:38:46,94] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false\n",
            "[2024-10-27 15:38:46,95] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false\n",
            "[2024-10-27 15:38:46,98] [info] Database closed\n",
            "[2024-10-27 15:38:46,98] [info] Stream materializer shut down\n",
            "[2024-10-27 15:38:46,98] [info] WDL HTTP import resolver closed\n"
          ]
        }
      ],
      "source": [
        "! java -jar cromwell-87.jar \\\n",
        "run /content/drive/MyDrive/dags/cromwell-test.wdl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_toRpaqesWk"
      },
      "source": [
        "WDL jest językiem deklaratywnym, co oznacza, że koncentruje się na tym, co należy zrobić, a nie na tym, jak to wykonać. Użytkownik opisuje dane wejściowe, polecenia i dane wyjściowe każdego kroku, a silnik (w naszym przypadku Cromwell) obsługuje planowanie zadań, zarządzanie zależnościami i przechowywanie plików.\n",
        "\n",
        "Na dzisiejszych zajęciach będziemy używać Cromwell w trybie `run` który jest polecany do budowania oraz testowania potoków ze względu na prostotę obługi oraz łatwość.\n",
        "\n",
        "Tryb `run` jest najlepszy do szybkiego wykonywania pojedynczych potoków na komputerze lokalnym. Jest prosty w użyciu, nie wymaga konfiguracji serwera, dzięki czemu doskonale nadaje się do testowania i debugowania. Jest on jednak ograniczony ze względu na możliwość uruchomienia tylko jednego potoku na raz oraz brak możliwości wznowienia analizy po nagłym przerwaniu.\n",
        "\n",
        "Tryb `server` działa jako usługa z interfejsem API HTTP, umożliwiając jednoczesne zarządzanie i monitorowanie wielu przepływów pracy. Tryb ten nadaje się do rozwiązań produkcyjnych lub dla wielu użytkowników, umożliwiając automatyczne przesyłanie, monitorowanie w czasie rzeczywistym i kolejkowanie przepływów pracy. Wymaga dodatkowej konfiguracji, takiej jak zapasowa baza danych, w celu zapewnienia odporności na nagłe przerwania oraz skalowalności.\n",
        "\n",
        "\n",
        "***\n",
        "### Struktura skrytpów WDL\n",
        "\n",
        "W folderze `dags` w pliku `alignment.wdl` zapisany jest krótki potok przetwarzania danych mający na celu uliniowienie plików FASTQ oraz konwersję wynikowego pliku do formatu BAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oGt5BBjiesWk",
        "outputId": "dafc6dbe-f3a4-4c9d-bc73-5431fe9b083f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "version 1.0\n",
            "\n",
            "workflow alignment_pipeline {\n",
            "    # Określenie plików wejściowych dla całego potoku\n",
            "    input {\n",
            "        File ref_fasta\n",
            "        File ref_dict\n",
            "        File ref_fasta_fai\n",
            "        File ref_fasta_amb\n",
            "        File ref_fasta_ann\n",
            "        File ref_fasta_bwt\n",
            "        File ref_fasta_pac\n",
            "        File ref_fasta_sa\n",
            "        File mother_fastq\n",
            "    }\n",
            "\n",
            "    # Etap 1: Uruchomienie BWA MEM\n",
            "    call BwaMem {\n",
            "        input:\n",
            "            ref_fasta = ref_fasta,\n",
            "            ref_fasta_amb = ref_fasta_amb,\n",
            "            ref_fasta_ann = ref_fasta_ann,\n",
            "            ref_fasta_bwt = ref_fasta_bwt,\n",
            "            ref_fasta_pac = ref_fasta_pac,\n",
            "            ref_fasta_sa = ref_fasta_sa,\n",
            "            fastq = mother_fastq\n",
            "    }\n",
            "\n",
            "    # Etap 2: Konwersja SAM do BAM\n",
            "    call SamToBam {\n",
            "        input:\n",
            "            sam_file = BwaMem.sam_file\n",
            "    }\n",
            "\n",
            "    # Określenie pliku wynikowego całego potoku\n",
            "    output {\n",
            "        File bam_file = SamToBam.bam_file\n",
            "        File bai_file = SamToBam.bai_file\n",
            "    }\n",
            "}\n",
            "\n",
            "# Informacje do uruchomienia etapu BWA MEM\n",
            "task BwaMem {\n",
            "    # Określenie plików wejściowych dla etapu BWA MEM\n",
            "    input {\n",
            "        File ref_fasta\n",
            "        File ref_fasta_amb\n",
            "        File ref_fasta_ann\n",
            "        File ref_fasta_bwt\n",
            "        File ref_fasta_pac\n",
            "        File ref_fasta_sa\n",
            "        File fastq\n",
            "    }\n",
            "\n",
            "    # Uruchomienie programu\n",
            "    command {\n",
            "        bwa mem -p ~{ref_fasta} ~{fastq} > mother.sam\n",
            "    }\n",
            "\n",
            "    # Określenie pliku wynikowego dla etapu BWA MEM\n",
            "    output {\n",
            "        File sam_file = \"mother.sam\"\n",
            "    }\n",
            "}\n",
            "\n",
            "# Task for converting SAM to BAM\n",
            "task SamToBam {\n",
            "    # Określenie plików wejściowych dla etapu konwersji\n",
            "    input {\n",
            "        File sam_file\n",
            "    }\n",
            "\n",
            "    # Wykonanie komendy konwersji\n",
            "    command {\n",
            "        samtools view -b ~{sam_file} | samtools addreplacerg -r '@RG\\tID:mother\\tSM:mother' - | samtools sort -o mother.bam\n",
            "        samtools index mother.bam \n",
            "    }\n",
            "\n",
            "    # Określenie pliku wynikowego dla etapu konwersji\n",
            "    output {\n",
            "        File bam_file = \"mother.bam\"\n",
            "        File bai_file = \"mother.bam.bai\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "! cat drive/MyDrive/dags/alignment.wdl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MK4d76GesWk"
      },
      "source": [
        "Schemat przepływu pracy WDL składa się z opisów przepływów pracy (Workflows) i zadań (Tasks):\n",
        "\n",
        "* **Workflow:** Definiuje wysokopoziomową sekwencję kroków i przepływ danych. Przepływ pracy łączy wiele zadań i ustanawia logiczne zależności między nimi.\n",
        "* **Task:** Definiuje poszczególne kroki w ramach przepływu pracy. Każde zadanie określa instrukcje wiersza poleceń, dane wejściowe i wyjściowe dla określonego kroku obliczeniowego.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Zadanie 7_1:</b> Przyglądając się plikowi <b>dags/alignment.wdl</b> podaj nazwy obydwu kroków oraz jakie przyjmują pliki wejściowe\n",
        "</div>\n",
        "\n",
        "W pliku `alignment-inputs.json` podane są ścieżki do plików które określone są jako pliki wejściowe na początku pliku wdl `alignment.wdl`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w2xFpoiaesWk",
        "outputId": "ced85f4f-c4fc-41ac-aab3-916b4934f4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"alignment_pipeline.ref_fasta\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.fasta\",\n",
            "  \"alignment_pipeline.ref_dict\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.dict\",\n",
            "  \"alignment_pipeline.ref_fasta_fai\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.fasta.fai\",\n",
            "  \"alignment_pipeline.ref_fasta_amb\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.fasta.amb\",\n",
            "  \"alignment_pipeline.ref_fasta_ann\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.fasta.ann\",\n",
            "  \"alignment_pipeline.ref_fasta_bwt\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.fasta.bwt\",\n",
            "  \"alignment_pipeline.ref_fasta_pac\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.fasta.pac\",\n",
            "  \"alignment_pipeline.ref_fasta_sa\": \"/tmp/jovyan/work/git/edugen_pub/ref/ref.fasta.sa\",\n",
            "  \"alignment_pipeline.mother_fastq\": \"/tmp/jovyan/work/git/edugen_pub/fastq/mother.fq\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "! cat drive/MyDrive/dags/alignment-inputs.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install udocker"
      ],
      "metadata": {
        "id": "KEv-INqBtJgo",
        "outputId": "713930e8-4882-448d-941a-17087b7916e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting udocker\n",
            "  Downloading udocker-1.3.17-py2.py3-none-any.whl.metadata (37 kB)\n",
            "Downloading udocker-1.3.17-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.6/119.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: udocker\n",
            "Successfully installed udocker-1.3.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "udocker --allow-root install"
      ],
      "metadata": {
        "id": "TZzuDP6vtOic",
        "outputId": "5c973d6d-7d8c-43af-900f-9c1c5dee911a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Info: creating repo: /root/.udocker\n",
            "Info: udocker command line interface 1.3.17\n",
            "Info: searching for udockertools >= 1.2.11\n",
            "Info: installing udockertools 1.2.11\n",
            "Info: installation of udockertools successful\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p shared"
      ],
      "metadata": {
        "id": "q2wzbigUt7SI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 shared"
      ],
      "metadata": {
        "id": "bDYs_Si82dp2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root run -p 8888:8888 \\\n",
        "-v $PWD/shared:/tmp/jovyan/work \\\n",
        "-e HOME=/tmp/jovyan \\\n",
        "-e DS_LAB_GCS_KEY=/tmp/dummy \\\n",
        "-e USER=jovyan \\\n",
        "biodatageeks/ds-notebook:spark-edugen-2.4.3-0.1.7-ga024cfc \\\n",
        "jupyter-lab --ip='*' --NotebookApp.token='' --NotebookApp.password=''"
      ],
      "metadata": {
        "id": "-GUUDmzUtQiR",
        "outputId": "cc1ee551-d740-409e-a217-867cbf019e9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Info: downloading layer sha256:8133bbf9a032f37a77ed68dddcfe9994325a2502dc1fa88b09e4200bffadf3f3\n",
            "Info: downloading layer sha256:27c7c87504d48672b6ae6c3fb3c5137b65f053ec706251f70a9a033acc317e84\n",
            "Info: downloading layer sha256:5badc6b00464250a15d6cfdf1bf5a46a54de19d25ed903e7db6cc4997672416f\n",
            "Info: downloading layer sha256:be2ed4fde04c160702f0c7a49f0161f4a9ed5d02645e931661dee8a480c8a42b\n",
            "Info: downloading layer sha256:fbfa651457e20fcfad737a1a130f4918a83668525729d49294240551a07ee46d\n",
            "Info: downloading layer sha256:9f8553e4abd1da5942556d8c269a64270028cc56dc28862503817ea901cb2f0b\n",
            "Info: downloading layer sha256:bb22f9360ecec1b5105434d03ab0071447aa52a9d1c3e5663f8db13e88c1ebbe\n",
            "Info: downloading layer sha256:e53c80fc815926e056189fbf8f1ff2366919859b41624b7586c28daf69f5bb69\n",
            "Info: downloading layer sha256:06ea1d780c3581293c47514a320c4044de49959a36a34b5a5e1f813301423f2a\n",
            "Info: downloading layer sha256:cca00083c93b5f50415827838acd7abc969a4a1d5e875e66c653a6be24bcb603\n",
            "Info: downloading layer sha256:719fb45e950bf1f51e0209c002ca00e3ba41d35d7087b88d071d9b43e7f393f7\n",
            "Info: downloading layer sha256:de958466fcc6f92e3d93e30c8e273318815333cfe38d1c81a9cd15bb7d103daa\n",
            "Info: downloading layer sha256:959295f0ce27cc05ad279824c6885b94715239273f6f669972f75c8b7a6ef927\n",
            "Info: downloading layer sha256:91afc9f128a284ec5f6a3dd7230ae2f6d7a26a8fba8e9d7b047cf51fa1f3c24e\n",
            "Info: downloading layer sha256:451a3354f2f8f22980027aef36721548f0f44259ef1875e7cc6aa964440fbc66\n",
            "Info: downloading layer sha256:ed8aa5bf0ad14b9f14816f4ba41299f8660df9a9bdd899dd7606dc460b8e4137\n",
            "Info: downloading layer sha256:c234406db90a5b7be4dfddce7cd43714637b2990ebba83cc9126d2a17b53da52\n",
            "Info: downloading layer sha256:dea4b8bb3e44e31fcb567998f76c256470cf95ab15e4abff158af149791f4959\n",
            "Info: downloading layer sha256:fdbd0c46878186f0c4218a0d9ee2e553693591a625fa91f09b173d37cc65f7ae\n",
            "Info: downloading layer sha256:c7801c4c2266f6d125e1c77477f212b431df72d1ece0d78a8ab2aba524b16fe4\n",
            "Info: downloading layer sha256:bc44f6c66f2863fc0c4e4a996be1cd0a3b7bc42afe65230a29bd7515bb6825ca\n",
            "Info: downloading layer sha256:dd24ea1df1ce0c76b33ec126ed23da5c394a9d0532d5d97f6a9d5a9f1c23599d\n",
            "Info: downloading layer sha256:515bd0996a73cf12cd3541c32d4ef942592db49fb56383f3de8cf2b85b272a59\n",
            "Info: downloading layer sha256:159abbadecb6e1836d2e914c59a2125780e1488a9d595745b8fc8a13cd528b01\n",
            "Info: downloading layer sha256:c621ecf4ce5e4604d8a205798269b075c52ee0dd97ffcd061e0018b28b38b83e\n",
            "Info: downloading layer sha256:2131d963a2631b57646c648aebe7f7a1e4b76bd0f5d09a8a62fd799980a33f13\n",
            "Info: downloading layer sha256:befcdddee3134097ef647ee51b9c45346c317b67a4f7f7232c2b8b43ceb12f5c\n",
            "Info: downloading layer sha256:e1fc119e3587b5ed85f7997507c0bf4f0a142c5559aa1f398b1234841aaa24fb\n",
            "Info: downloading layer sha256:950ada586b8e2e223a0cbbe01608aa5096fee83561b14b61d15177fbd0858548\n",
            "Info: downloading layer sha256:729dee0bd7f757751dc12e1c021e1c0c34e795bed38d510eb6cb69bb3fa48b7e\n",
            "Info: downloading layer sha256:d5fb4848d4879e7bb81ba9b3ef5c8bb7c06c4f79d1033d1bb259d4c6b6e0720d\n",
            "Info: downloading layer sha256:3e52f2f6b357fef06f30861417ab28f60271396b3d493662a1444e1d0a0cf783\n",
            "Info: downloading layer sha256:003ea910f24e049f70b0d329040c1d1131617b60a44a9aa483103231d33181e9\n",
            "Info: downloading layer sha256:59afda8d480fb67ea067734a9783df526caf9b341275d0df9a3f81eaf0f9ab93\n",
            "Info: downloading layer sha256:62e8f63b10e69606ac8f0b3c71683305c819442f0a90571a3bf7c20cadf8e4db\n",
            "Info: downloading layer sha256:a097485f0e3fe9c5e3de55fcad0459f1605f238feb85aa82a61af0c63eefa1c6\n",
            "Info: downloading layer sha256:3ad445b5df9032a61b28c8d21153425f010b97a8e541af1ec06196aac4e8d61e\n",
            "Info: downloading layer sha256:4464ff844941cc5d8131e00e27022a89408c733526f5c07fd5699581912292bd\n",
            "Info: downloading layer sha256:f99e0db377e622ecdf84b81dd48a39df0d03ec2189b2ba2f6aa82de889b18b87\n",
            "Info: downloading layer sha256:13a0542cd090e7b1105ba3246bd1423f490250a1353805a984bb4641fedfbb7f\n",
            "Info: downloading layer sha256:eee1f0552c9bf5107d6e374ac87f47560706488041ee17b92d480fbef7134746\n",
            "Info: downloading layer sha256:4e643cc37772c094642f3168c56d1fcbcc9a07ecf72dbb5afdc35baf57e8bc29\n",
            "Info: downloading layer sha256:2821b8e766f41f4f148dc2d378c41d60f3d2cbe6f03b2585dd5653c3873740ef\n",
            "Info: downloading layer sha256:97058a342707e39028c2597a4306fd3b1a2ebaf5423f8e514428c73fa508960c\n",
            "Info: downloading layer sha256:692c352adcf2821d6988021248da6b276cb738808f69dcc7bbb74a9c952146f7\n",
            "Warning: this container exposes TCP/IP ports\n",
            " \n",
            " ****************************************************************************** \n",
            " *                                                                            * \n",
            " *               STARTING 30b1a0b8-4d03-35ee-bfb5-df9d2f01fc7d                * \n",
            " *                                                                            * \n",
            " ****************************************************************************** \n",
            " executing: entrypoint.sh\n",
            "+ export TMP_HOME=/tmp/jovyan\n",
            "+ TMP_HOME=/tmp/jovyan\n",
            "+ cp -r /tmp/jovyan/.sdkman /tmp/jovyan\n",
            "cp: '/tmp/jovyan/.sdkman' and '/tmp/jovyan/.sdkman' are the same file\n",
            "+ source /tmp/jovyan/.sdkman/bin/sdkman-init.sh\n",
            "++ '[' -z '' ']'\n",
            "++ export SDKMAN_VERSION=5.9.2+613\n",
            "++ SDKMAN_VERSION=5.9.2+613\n",
            "++ '[' -z '' ']'\n",
            "++ export SDKMAN_CANDIDATES_API=https://api.sdkman.io/2\n",
            "++ SDKMAN_CANDIDATES_API=https://api.sdkman.io/2\n",
            "++ '[' -z '' ']'\n",
            "++ export SDKMAN_DIR=/tmp/jovyan/.sdkman\n",
            "++ SDKMAN_DIR=/tmp/jovyan/.sdkman\n",
            "+++ infer_platform\n",
            "+++ local kernel\n",
            "+++ local machine\n",
            "++++ uname -s\n",
            "+++ kernel=Linux\n",
            "++++ uname -m\n",
            "+++ machine=x86_64\n",
            "+++ case $kernel in\n",
            "+++ case $machine in\n",
            "+++ echo LinuxX64\n",
            "++ SDKMAN_PLATFORM=LinuxX64\n",
            "++ export SDKMAN_PLATFORM\n",
            "++ cygwin=false\n",
            "++ darwin=false\n",
            "++ solaris=false\n",
            "++ freebsd=false\n",
            "+++ uname -s\n",
            "++ SDKMAN_KERNEL=Linux\n",
            "++ case \"${SDKMAN_KERNEL}\" in\n",
            "++ zsh_shell=false\n",
            "++ bash_shell=false\n",
            "++ [[ -n '' ]]\n",
            "++ bash_shell=true\n",
            "++ OLD_IFS=' \t\n",
            "'\n",
            "++ IFS='\n",
            "'\n",
            "++ scripts=($(find \"${SDKMAN_DIR}/src\" \"${SDKMAN_DIR}/ext\" -type f -name 'sdkman-*.sh'))\n",
            "+++ find /tmp/jovyan/.sdkman/src /tmp/jovyan/.sdkman/ext -type f -name 'sdkman-*.sh'\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-install.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-main.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-selfupdate.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-help.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-cache.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-path-helpers.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-list.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-current.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-utils.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-version.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-upgrade.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-update.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-home.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-flush.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-env.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-env-helpers.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-offline.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-use.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-default.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-uninstall.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-availability.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-broadcast.sh\n",
            "++ IFS=' \t\n",
            "'\n",
            "++ unset OLD_IFS scripts f\n",
            "++ '[' -f /tmp/jovyan/.sdkman/etc/config ']'\n",
            "++ source /tmp/jovyan/.sdkman/etc/config\n",
            "+++ sdkman_auto_answer=false\n",
            "+++ sdkman_auto_selfupdate=false\n",
            "+++ sdkman_insecure_ssl=false\n",
            "+++ sdkman_curl_connect_timeout=7\n",
            "+++ sdkman_curl_max_time=10\n",
            "+++ sdkman_beta_channel=false\n",
            "+++ sdkman_debug_mode=false\n",
            "+++ sdkman_colour_enable=true\n",
            "+++ sdkman_auto_env=false\n",
            "++ [[ ! -f /tmp/jovyan/.sdkman/var/delay_upgrade ]]\n",
            "++ [[ -z 7 ]]\n",
            "++ [[ -z 10 ]]\n",
            "++ [[ -z '' ]]\n",
            "++ sdkman_curl_retry=0\n",
            "++ [[ -z '' ]]\n",
            "++ sdkman_curl_retry_max_time=60\n",
            "++ [[ -z '' ]]\n",
            "++ sdkman_curl_continue=true\n",
            "++ SDKMAN_CANDIDATES_CACHE=/tmp/jovyan/.sdkman/var/candidates\n",
            "++ SDKMAN_CANDIDATES_CSV=ant,asciidoctorj,ballerina,bpipe,btrace,ceylon,concurnas,crash,cuba,cxf,doctoolchain,dotty,gaiden,glide,gradle,gradleprofiler,grails,groovy,groovyserv,http4k,infrastructor,java,jbake,jbang,karaf,kotlin,kscript,lazybones,leiningen,maven,micronaut,mulefd,mvnd,sbt,scala,spark,springboot,sshoogr,test,tomcat,vertx,visualvm\n",
            "++ __sdkman_echo_debug 'Setting candidates csv: ant,asciidoctorj,ballerina,bpipe,btrace,ceylon,concurnas,crash,cuba,cxf,doctoolchain,dotty,gaiden,glide,gradle,gradleprofiler,grails,groovy,groovyserv,http4k,infrastructor,java,jbake,jbang,karaf,kotlin,kscript,lazybones,leiningen,maven,micronaut,mulefd,mvnd,sbt,scala,spark,springboot,sshoogr,test,tomcat,vertx,visualvm'\n",
            "++ [[ false == \\t\\r\\u\\e ]]\n",
            "++ [[ false == \\t\\r\\u\\e ]]\n",
            "++ IFS=,\n",
            "++ read -a SDKMAN_CANDIDATES\n",
            "++ export SDKMAN_CANDIDATES_DIR=/tmp/jovyan/.sdkman/candidates\n",
            "++ SDKMAN_CANDIDATES_DIR=/tmp/jovyan/.sdkman/candidates\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/ant/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/ant/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/ant/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/asciidoctorj/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/asciidoctorj/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/asciidoctorj/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/ballerina/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/ballerina/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/ballerina/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/bpipe/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/bpipe/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/bpipe/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/btrace/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/btrace/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/btrace/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/ceylon/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/ceylon/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/ceylon/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/concurnas/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/concurnas/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/concurnas/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/crash/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/crash/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/crash/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/cuba/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/cuba/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/cuba/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/cxf/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/cxf/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/cxf/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/doctoolchain/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/doctoolchain/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/doctoolchain/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/dotty/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/dotty/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/dotty/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/gaiden/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/gaiden/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/gaiden/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/glide/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/glide/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/glide/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/gradle/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/gradle/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/gradle/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/gradleprofiler/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/gradleprofiler/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/gradleprofiler/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/grails/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/grails/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/grails/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/groovy/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/groovy/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/groovy/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/groovyserv/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/groovyserv/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/groovyserv/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/http4k/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/http4k/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/http4k/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/infrastructor/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/infrastructor/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/infrastructor/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/java/current ]]\n",
            "++ __sdkman_export_candidate_home java /tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ local candidate_name=java\n",
            "++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ echo java\n",
            "+++ tr '[:lower:]' '[:upper:]'\n",
            "++ local candidate_home_var=JAVA_HOME\n",
            "+++ echo JAVA_HOME\n",
            "++ export JAVA_HOME=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ JAVA_HOME=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ __sdkman_prepend_candidate_to_path /tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ local candidate_dir candidate_bin_dir\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ __sdkman_determine_candidate_bin_dir /tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ [[ -d /tmp/jovyan/.sdkman/candidates/java/current/bin ]]\n",
            "+++ echo /tmp/jovyan/.sdkman/candidates/java/current/bin\n",
            "++ candidate_bin_dir=/tmp/jovyan/.sdkman/candidates/java/current/bin\n",
            "++ echo /opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ grep -q /tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ PATH=/tmp/jovyan/.sdkman/candidates/java/current/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ unset CANDIDATE_BIN_DIR\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/jbake/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/jbake/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/jbake/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/jbang/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/jbang/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/jbang/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/karaf/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/karaf/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/karaf/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/kotlin/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/kotlin/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/kotlin/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/kscript/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/kscript/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/kscript/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/lazybones/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/lazybones/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/lazybones/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/leiningen/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/leiningen/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/leiningen/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/maven/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/maven/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/maven/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/micronaut/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/micronaut/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/micronaut/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/mulefd/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/mulefd/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/mulefd/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/mvnd/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/mvnd/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/mvnd/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/sbt/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/sbt/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/sbt/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/scala/current ]]\n",
            "++ __sdkman_export_candidate_home scala /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ local candidate_name=scala\n",
            "++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ echo scala\n",
            "+++ tr '[:lower:]' '[:upper:]'\n",
            "++ local candidate_home_var=SCALA_HOME\n",
            "+++ echo SCALA_HOME\n",
            "++ export SCALA_HOME=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ SCALA_HOME=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ __sdkman_prepend_candidate_to_path /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ local candidate_dir candidate_bin_dir\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ __sdkman_determine_candidate_bin_dir /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ [[ -d /tmp/jovyan/.sdkman/candidates/scala/current/bin ]]\n",
            "+++ echo /tmp/jovyan/.sdkman/candidates/scala/current/bin\n",
            "++ candidate_bin_dir=/tmp/jovyan/.sdkman/candidates/scala/current/bin\n",
            "++ echo /tmp/jovyan/.sdkman/candidates/java/current/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ grep -q /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ PATH=/tmp/jovyan/.sdkman/candidates/scala/current/bin:/tmp/jovyan/.sdkman/candidates/java/current/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ unset CANDIDATE_BIN_DIR\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/spark/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/spark/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/spark/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/springboot/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/springboot/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/springboot/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/sshoogr/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/sshoogr/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/sshoogr/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/test/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/test/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/test/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/tomcat/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/tomcat/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/tomcat/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/vertx/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/vertx/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/vertx/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/visualvm/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/visualvm/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/visualvm/current ]]\n",
            "++ unset candidate_name candidate_dir\n",
            "++ export PATH\n",
            "++ [[ false == \\t\\r\\u\\e ]]\n",
            "+ echo jupyter-lab '--ip=*' --NotebookApp.token= --NotebookApp.password=\n",
            "jupyter-lab --ip=* --NotebookApp.token= --NotebookApp.password=\n",
            "+ BIODATAGEEKS_REPOS=https://oss.sonatype.org/content/repositories/snapshots/\n",
            "+ : /tmp/dummy\n",
            "+ export SECRETS_MOUNT_DIR=/tmp/secrets\n",
            "+ SECRETS_MOUNT_DIR=/tmp/secrets\n",
            "+ mkdir -p /tmp/secrets\n",
            "+ echo /tmp/dummy\n",
            "+ export GOOGLE_APPLICATION_CREDENTIALS=/tmp/secrets/ds-lab-sa.json\n",
            "+ GOOGLE_APPLICATION_CREDENTIALS=/tmp/secrets/ds-lab-sa.json\n",
            "++ cat /tmp/secrets/ds-lab-sa.json\n",
            "++ jq .project_id\n",
            "++ sed 's/\"//g'\n",
            "parse error: Invalid numeric literal at line 2, column 0\n",
            "+ export PROJECT_ID=\n",
            "+ PROJECT_ID=\n",
            "+ envsubst\n",
            "+ '[' true == true ']'\n",
            "+ SPARK_PACKAGES='--packages org.biodatageeks:sequila_2.11:0.5.20,io.projectglow:glow-spark2_2.11:0.6.0,org.biodatageeks:seqtender_2.11:0.3.7'\n",
            "+ '[' true == true ']'\n",
            "+ export MLFLOW_TRACKING_URI=http://localhost:5000\n",
            "+ MLFLOW_TRACKING_URI=http://localhost:5000\n",
            "+ export PYSPARK_PYTHON=python3\n",
            "+ PYSPARK_PYTHON=python3\n",
            "+ export 'PYSPARK_SUBMIT_ARGS=--repositories https://oss.sonatype.org/content/repositories/snapshots/   --jars /tmp/gcs-connector-hadoop2-1.9.17-shaded.jar,/tmp/google-cloud-nio-0.120.0-alpha-shaded.jar   --conf spark.hadoop.google.cloud.auth.service.account.enable=true   --conf spark.hadoop.google.cloud.auth.service.account.json.keyfile=/tmp/secrets/ds-lab-sa.json   --conf spark.kubernetes.driverEnv.GCS_PROJECT_ID=   --conf spark.kubernetes.driverEnv.GOOGLE_APPLICATION_CREDENTIALS=/tmp/secrets/ds-lab-sa.json   --conf spark.executorEnv.GCS_PROJECT_ID=   --conf spark.executorEnv.GOOGLE_APPLICATION_CREDENTIALS=/tmp/secrets/ds-lab-sa.json   --conf spark.kubernetes.driver.secrets.ds-lab-sa-secret=/tmp/secrets   --conf spark.kubernetes.executor.secrets.ds-lab-sa-secret=/tmp/secrets   --conf spark.hadoop.fs.gs.project.id=   --conf spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem   --conf spark.hadoop.fs.AbstractFileSystem.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS   --master k8s://https://:   --conf spark.kubernetes.container.image=gcr.io/studiapodyplomowe/biodatageeks/spark-py:v2.4.3-edugen-0.1.7-g5a6ab7a   --conf spark.kubernetes.authenticate.driver.serviceAccountName=ds-lab-sa   --conf spark.kubernetes.authenticate.serviceAccountName=ds-lab-sa   --conf spark.kubernetes.executor.podNamePrefix=pyspark-exec-   --conf spark.kubernetes.executor.label.spark-owner=   --conf spark.kubernetes.executor.request.cores=0.4   --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.pvc-shared-pipeline.options.claimName=pvc-shared-pipeline   --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.pvc-shared-pipeline.mount.path=/mnt/data   --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.pvc-shared-pipeline.mount.readOnly=true   --conf spark.driver.port=29010   --conf spark.blockManager.port=29011   --conf spark.kubernetes.namespace=default   --conf spark.driver.host=jupyter-service-   --conf spark.driver.bindAddress=590eb0e62756   --conf spark.executorEnv.PYSPARK_PYTHON=python3   --packages org.biodatageeks:sequila_2.11:0.5.20,io.projectglow:glow-spark2_2.11:0.6.0,org.biodatageeks:seqtender_2.11:0.3.7    pyspark-shell'\n",
            "+ PYSPARK_SUBMIT_ARGS='--repositories https://oss.sonatype.org/content/repositories/snapshots/   --jars /tmp/gcs-connector-hadoop2-1.9.17-shaded.jar,/tmp/google-cloud-nio-0.120.0-alpha-shaded.jar   --conf spark.hadoop.google.cloud.auth.service.account.enable=true   --conf spark.hadoop.google.cloud.auth.service.account.json.keyfile=/tmp/secrets/ds-lab-sa.json   --conf spark.kubernetes.driverEnv.GCS_PROJECT_ID=   --conf spark.kubernetes.driverEnv.GOOGLE_APPLICATION_CREDENTIALS=/tmp/secrets/ds-lab-sa.json   --conf spark.executorEnv.GCS_PROJECT_ID=   --conf spark.executorEnv.GOOGLE_APPLICATION_CREDENTIALS=/tmp/secrets/ds-lab-sa.json   --conf spark.kubernetes.driver.secrets.ds-lab-sa-secret=/tmp/secrets   --conf spark.kubernetes.executor.secrets.ds-lab-sa-secret=/tmp/secrets   --conf spark.hadoop.fs.gs.project.id=   --conf spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem   --conf spark.hadoop.fs.AbstractFileSystem.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS   --master k8s://https://:   --conf spark.kubernetes.container.image=gcr.io/studiapodyplomowe/biodatageeks/spark-py:v2.4.3-edugen-0.1.7-g5a6ab7a   --conf spark.kubernetes.authenticate.driver.serviceAccountName=ds-lab-sa   --conf spark.kubernetes.authenticate.serviceAccountName=ds-lab-sa   --conf spark.kubernetes.executor.podNamePrefix=pyspark-exec-   --conf spark.kubernetes.executor.label.spark-owner=   --conf spark.kubernetes.executor.request.cores=0.4   --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.pvc-shared-pipeline.options.claimName=pvc-shared-pipeline   --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.pvc-shared-pipeline.mount.path=/mnt/data   --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.pvc-shared-pipeline.mount.readOnly=true   --conf spark.driver.port=29010   --conf spark.blockManager.port=29011   --conf spark.kubernetes.namespace=default   --conf spark.driver.host=jupyter-service-   --conf spark.driver.bindAddress=590eb0e62756   --conf spark.executorEnv.PYSPARK_PYTHON=python3   --packages org.biodatageeks:sequila_2.11:0.5.20,io.projectglow:glow-spark2_2.11:0.6.0,org.biodatageeks:seqtender_2.11:0.3.7    pyspark-shell'\n",
            "+ mkdir -p /tmp/jovyan/work/git\n",
            "+ cd /tmp/jovyan/work/git\n",
            "+ git clone https://github.com/IMID/edugen_pub\n",
            "Cloning into 'edugen_pub'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 196 (delta 93), reused 134 (delta 48), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (196/196), 5.54 MiB | 18.55 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "++ ls -1\n",
            "+ for dir in $( ls -1 )\n",
            "+ cd edugen_pub\n",
            "+ git pull --rebase\n",
            "Already up to date.\n",
            "Current branch main is up to date.\n",
            "+ cd ..\n",
            "+ cd /tmp/jovyan\n",
            "+ '[' false == true ']'\n",
            "+ tini -g -- jupyter-lab '--ip=*' --NotebookApp.token= --NotebookApp.password=\n",
            "[WARN  tini (3027)] Tini is not running as PID 1 .\n",
            "Zombie processes will not be re-parented to Tini, so zombie reaping won't work.\n",
            "To fix the problem, run Tini as PID 1.\n",
            "\u001b[32m[I 16:45:42.178 LabApp]\u001b[m Writing notebook server cookie secret to /tmp/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret\n",
            "\u001b[33m[W 16:45:43.735 LabApp]\u001b[m WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.\n",
            "\u001b[33m[W 16:45:43.735 LabApp]\u001b[m WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.\n",
            "\u001b[32m[I 16:45:45.921 LabApp]\u001b[m JupyterLab extension loaded from /opt/conda/lib/python3.8/site-packages/jupyterlab\n",
            "\u001b[32m[I 16:45:45.921 LabApp]\u001b[m JupyterLab application directory is /opt/conda/share/jupyter/lab\n",
            "[C 16:45:45.928 LabApp] Running as root is not recommended. Use --allow-root to bypass.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root ps"
      ],
      "metadata": {
        "id": "j5IS4BDqy7o8",
        "outputId": "b4d1e356-c74a-4800-dea7-9a19366aa1a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONTAINER ID                         P M NAMES              IMAGE               \n",
            "30b1a0b8-4d03-35ee-bfb5-df9d2f01fc7d . W                    biodatageeks/ds-notebook:spark-edugen-2.4.3-0.1.7-ga024cfc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root --help"
      ],
      "metadata": {
        "id": "rZ1XBIjH5KZ3",
        "outputId": "69d7fa1d-2a4a-4157-87e0-7a6450fd62e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Syntax:\n",
            "  udocker  [general_options] <command>  [command_options]  <command_args>\n",
            "\n",
            "  udocker [-h|--help|help]        :Display this help and exits\n",
            "  udocker [-V|--version|version]  :Display udocker and tarball version and exits\n",
            "\n",
            "General options common to all commands must appear before the command:\n",
            "  -D, --debug                   :Debug\n",
            "  -q, --quiet                   :Less verbosity\n",
            "  --insecure                    :Allow insecure non authenticated https\n",
            "  --repo=<directory>            :Use repository at directory\n",
            "  --allow-root                  :Allow execution by root NOT recommended\n",
            "  --config=<conf_file>          :Use configuration <conf_file>\n",
            "\n",
            "Commands:\n",
            "  --help [command]              :Command specific help\n",
            "  showconf                      :Print all configuration options\n",
            "\n",
            "  search <repo/expression>      :Search dockerhub for container images\n",
            "  pull <repo/image:tag>         :Pull container image from dockerhub\n",
            "  create <repo/image:tag>       :Create container from a pulled image\n",
            "  run <container_id|name>       :Execute created container\n",
            "  run <repo/image:tag>          :Pull, create and execute container\n",
            "\n",
            "  images -l                     :List container images\n",
            "  ps -m -s                      :List created containers\n",
            "  name <container_id> <name>    :Give name to container\n",
            "  rmname <name>                 :Delete name from container\n",
            "  rename <name> <new_name>      :Change container name\n",
            "  clone <container_id>          :Duplicate container\n",
            "  rm  <container-id|name>       :Delete container\n",
            "  rmi <repo/image:tag>          :Delete image\n",
            "  tag <repo/image:tag> <repo2/image2:tag2> :Tag image\n",
            "\n",
            "  import <tar> <repo/image:tag> :Import tar file (exported by docker)\n",
            "  import - <repo/image:tag>     :Import from stdin (exported by docker)\n",
            "  export -o <tar> <container>   :Export container directory tree to file\n",
            "  export - <container>          :Export container directory tree to stdin\n",
            "  load -i <exported-image>      :Load image from file (saved by docker)\n",
            "  load                          :Load image from stdin (saved by docker)\n",
            "  save -o <imagefile> <repo/image:tag>  :Save image with layers to file\n",
            "\n",
            "  inspect -p <repo/image:tag>   :Print image or container metadata\n",
            "  verify <repo/image:tag>       :Verify a pulled image\n",
            "  manifest inspect <repo/image:tag> :Print manifest metadata\n",
            "\n",
            "  udocker manifest inspect centos/centos8\n",
            "  udocker pull --platform=linux/arm64 centos/centos8\n",
            "  udocker tag centos/centos8  mycentos/centos8:arm64\n",
            "\n",
            "  protect <repo/image:tag>      :Protect repository\n",
            "  unprotect <repo/image:tag>    :Unprotect repository\n",
            "  protect <container>           :Protect container\n",
            "  unprotect <container>         :Unprotect container\n",
            "\n",
            "  mkrepo <top-repo-dir>         :Create another repository in location\n",
            "  setup --execmode=<mode>       :Change container execution mode\n",
            "  setup --nvidia                :Setup container to use nvidia GPU\n",
            "  setup --purge                 :clean mountpoints and files created by udocker\n",
            "  setup --fixperm               :attempt to fix file permissions\n",
            "\n",
            "  login                         :Login into docker repository\n",
            "  logout                        :Logout from docker repository\n",
            "\n",
            "Examples:\n",
            "  udocker search expression\n",
            "  udocker search quay.io/expression\n",
            "  udocker search --list-tags myimage\n",
            "  udocker pull myimage:mytag\n",
            "  udocker images\n",
            "  udocker create --name=mycontainer  myimage:mytag\n",
            "  udocker ps -m -s\n",
            "  udocker inspect mycontainer\n",
            "  udocker inspect -p mycontainer\n",
            "\n",
            "  udocker manifest inspect centos/centos8\n",
            "  udocker pull --platform=linux/arm64 centos/centos8\n",
            "  udocker tag centos/centos8  mycentos/centos8:arm64\n",
            "\n",
            "  udocker run  mycontainer  cat /etc/redhat-release\n",
            "  udocker run --hostauth --hostenv --bindhome  mycontainer\n",
            "  udocker run --user=root  mycontainer  yum install firefox\n",
            "  udocker run --hostauth --hostenv --bindhome mycontainer  firefox\n",
            "  udocker run --entrypoint=\"\" mycontainer  /bin/bash -i\n",
            "  udocker run --entrypoint=\"/bin/bash\" mycontainer -i\n",
            "\n",
            "  udocker clone --name=anotherc mycontainer\n",
            "  udocker rm anotherc\n",
            "\n",
            "  udocker mkrepo /data/myrepo\n",
            "  udocker --repo=/data/myrepo load -i docker-saved-repo.tar\n",
            "  udocker --repo=/data/myrepo images\n",
            "  udocker --repo=/data/myrepo run --user=$USER  myimage:mytag\n",
            "\n",
            "  udocker export -o myimage.tar mycontainer\n",
            "  udocker import myimage.tar mynewimage\n",
            "  udocker create --name=mynewc mynewimage\n",
            "  udocker export --clone -o mycontainer.tar mycontainer\n",
            "  udocker import --clone mycontainer.tar\n",
            "\n",
            "Notes:\n",
            " * by default the binaries, images and containers are placed in\n",
            "      $HOME/.udocker\n",
            " * by default the following host directories are mounted in the\n",
            "   container:\n",
            "      /dev /proc /sys /etc/resolv.conf /etc/host.conf /etc/hostname\n",
            " * to prevent the mount of the above directories use:\n",
            "      run  --nosysdirs  <container>\n",
            " * additional host directories to be mounted are specified with:\n",
            "      run --volume=/data:/mnt --volume=/etc/hosts  <container>\n",
            "      run --nosysdirs --volume=/dev --volume=/proc  <container>\n",
            " * udocker provides several execution modes that offer different\n",
            "   approaches and technologies to execute containers, they\n",
            "   can be selected using the setup command. See the setup help.\n",
            "      udocker setup --execmode=F3 fedx\n",
            "      udocker setup --execmode=R1 fedx\n",
            "      udocker setup --execmode=S1 fedx\n",
            "      udocker setup --help\n",
            " * udocker facilitates the usage of nvidia drivers within containers\n",
            "      udocker setup --nvidia fedx\n",
            "\n",
            "See: https://github.com/indigo-dc/udocker/blob/master/SUMMARY.md\n",
            "            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root run 30b1a0b8-4d03-35ee-bfb5-df9d2f01fc7d ls /tmp/dummy"
      ],
      "metadata": {
        "id": "GHmI0gEN4afZ",
        "outputId": "947dbb77-3506-453d-9076-30f97c564646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: this container exposes TCP/IP ports\n",
            " \n",
            " ****************************************************************************** \n",
            " *                                                                            * \n",
            " *               STARTING 30b1a0b8-4d03-35ee-bfb5-df9d2f01fc7d                * \n",
            " *                                                                            * \n",
            " ****************************************************************************** \n",
            " executing: entrypoint.sh\n",
            "+ export TMP_HOME=/tmp/jovyan\n",
            "+ TMP_HOME=/tmp/jovyan\n",
            "+ cp -r /tmp/jovyan/.sdkman /tmp/jovyan\n",
            "cp: '/tmp/jovyan/.sdkman' and '/tmp/jovyan/.sdkman' are the same file\n",
            "+ source /tmp/jovyan/.sdkman/bin/sdkman-init.sh\n",
            "++ '[' -z '' ']'\n",
            "++ export SDKMAN_VERSION=5.9.2+613\n",
            "++ SDKMAN_VERSION=5.9.2+613\n",
            "++ '[' -z '' ']'\n",
            "++ export SDKMAN_CANDIDATES_API=https://api.sdkman.io/2\n",
            "++ SDKMAN_CANDIDATES_API=https://api.sdkman.io/2\n",
            "++ '[' -z '' ']'\n",
            "++ export SDKMAN_DIR=/tmp/jovyan/.sdkman\n",
            "++ SDKMAN_DIR=/tmp/jovyan/.sdkman\n",
            "+++ infer_platform\n",
            "+++ local kernel\n",
            "+++ local machine\n",
            "++++ uname -s\n",
            "+++ kernel=Linux\n",
            "++++ uname -m\n",
            "+++ machine=x86_64\n",
            "+++ case $kernel in\n",
            "+++ case $machine in\n",
            "+++ echo LinuxX64\n",
            "++ SDKMAN_PLATFORM=LinuxX64\n",
            "++ export SDKMAN_PLATFORM\n",
            "++ cygwin=false\n",
            "++ darwin=false\n",
            "++ solaris=false\n",
            "++ freebsd=false\n",
            "+++ uname -s\n",
            "++ SDKMAN_KERNEL=Linux\n",
            "++ case \"${SDKMAN_KERNEL}\" in\n",
            "++ zsh_shell=false\n",
            "++ bash_shell=false\n",
            "++ [[ -n '' ]]\n",
            "++ bash_shell=true\n",
            "++ OLD_IFS=' \t\n",
            "'\n",
            "++ IFS='\n",
            "'\n",
            "++ scripts=($(find \"${SDKMAN_DIR}/src\" \"${SDKMAN_DIR}/ext\" -type f -name 'sdkman-*.sh'))\n",
            "+++ find /tmp/jovyan/.sdkman/src /tmp/jovyan/.sdkman/ext -type f -name 'sdkman-*.sh'\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-install.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-main.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-selfupdate.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-help.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-cache.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-path-helpers.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-list.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-current.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-utils.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-version.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-upgrade.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-update.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-home.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-flush.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-env.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-env-helpers.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-offline.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-use.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-default.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-uninstall.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-availability.sh\n",
            "++ for f in \"${scripts[@]}\"\n",
            "++ source /tmp/jovyan/.sdkman/src/sdkman-broadcast.sh\n",
            "++ IFS=' \t\n",
            "'\n",
            "++ unset OLD_IFS scripts f\n",
            "++ '[' -f /tmp/jovyan/.sdkman/etc/config ']'\n",
            "++ source /tmp/jovyan/.sdkman/etc/config\n",
            "+++ sdkman_auto_answer=false\n",
            "+++ sdkman_auto_selfupdate=false\n",
            "+++ sdkman_insecure_ssl=false\n",
            "+++ sdkman_curl_connect_timeout=7\n",
            "+++ sdkman_curl_max_time=10\n",
            "+++ sdkman_beta_channel=false\n",
            "+++ sdkman_debug_mode=false\n",
            "+++ sdkman_colour_enable=true\n",
            "+++ sdkman_auto_env=false\n",
            "++ [[ ! -f /tmp/jovyan/.sdkman/var/delay_upgrade ]]\n",
            "++ [[ -z 7 ]]\n",
            "++ [[ -z 10 ]]\n",
            "++ [[ -z '' ]]\n",
            "++ sdkman_curl_retry=0\n",
            "++ [[ -z '' ]]\n",
            "++ sdkman_curl_retry_max_time=60\n",
            "++ [[ -z '' ]]\n",
            "++ sdkman_curl_continue=true\n",
            "++ SDKMAN_CANDIDATES_CACHE=/tmp/jovyan/.sdkman/var/candidates\n",
            "++ SDKMAN_CANDIDATES_CSV=ant,asciidoctorj,ballerina,bpipe,btrace,ceylon,concurnas,crash,cuba,cxf,doctoolchain,dotty,gaiden,glide,gradle,gradleprofiler,grails,groovy,groovyserv,http4k,infrastructor,java,jbake,jbang,karaf,kotlin,kscript,lazybones,leiningen,maven,micronaut,mulefd,mvnd,sbt,scala,spark,springboot,sshoogr,test,tomcat,vertx,visualvm\n",
            "++ __sdkman_echo_debug 'Setting candidates csv: ant,asciidoctorj,ballerina,bpipe,btrace,ceylon,concurnas,crash,cuba,cxf,doctoolchain,dotty,gaiden,glide,gradle,gradleprofiler,grails,groovy,groovyserv,http4k,infrastructor,java,jbake,jbang,karaf,kotlin,kscript,lazybones,leiningen,maven,micronaut,mulefd,mvnd,sbt,scala,spark,springboot,sshoogr,test,tomcat,vertx,visualvm'\n",
            "++ [[ false == \\t\\r\\u\\e ]]\n",
            "++ [[ false == \\t\\r\\u\\e ]]\n",
            "++ IFS=,\n",
            "++ read -a SDKMAN_CANDIDATES\n",
            "++ export SDKMAN_CANDIDATES_DIR=/tmp/jovyan/.sdkman/candidates\n",
            "++ SDKMAN_CANDIDATES_DIR=/tmp/jovyan/.sdkman/candidates\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/ant/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/ant/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/ant/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/asciidoctorj/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/asciidoctorj/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/asciidoctorj/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/ballerina/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/ballerina/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/ballerina/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/bpipe/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/bpipe/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/bpipe/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/btrace/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/btrace/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/btrace/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/ceylon/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/ceylon/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/ceylon/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/concurnas/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/concurnas/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/concurnas/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/crash/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/crash/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/crash/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/cuba/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/cuba/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/cuba/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/cxf/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/cxf/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/cxf/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/doctoolchain/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/doctoolchain/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/doctoolchain/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/dotty/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/dotty/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/dotty/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/gaiden/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/gaiden/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/gaiden/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/glide/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/glide/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/glide/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/gradle/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/gradle/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/gradle/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/gradleprofiler/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/gradleprofiler/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/gradleprofiler/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/grails/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/grails/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/grails/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/groovy/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/groovy/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/groovy/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/groovyserv/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/groovyserv/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/groovyserv/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/http4k/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/http4k/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/http4k/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/infrastructor/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/infrastructor/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/infrastructor/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/java/current ]]\n",
            "++ __sdkman_export_candidate_home java /tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ local candidate_name=java\n",
            "++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ echo java\n",
            "+++ tr '[:lower:]' '[:upper:]'\n",
            "++ local candidate_home_var=JAVA_HOME\n",
            "+++ echo JAVA_HOME\n",
            "++ export JAVA_HOME=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ JAVA_HOME=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ __sdkman_prepend_candidate_to_path /tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ local candidate_dir candidate_bin_dir\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ __sdkman_determine_candidate_bin_dir /tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/java/current\n",
            "+++ [[ -d /tmp/jovyan/.sdkman/candidates/java/current/bin ]]\n",
            "+++ echo /tmp/jovyan/.sdkman/candidates/java/current/bin\n",
            "++ candidate_bin_dir=/tmp/jovyan/.sdkman/candidates/java/current/bin\n",
            "++ echo /opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ grep -q /tmp/jovyan/.sdkman/candidates/java/current\n",
            "++ PATH=/tmp/jovyan/.sdkman/candidates/java/current/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ unset CANDIDATE_BIN_DIR\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/jbake/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/jbake/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/jbake/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/jbang/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/jbang/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/jbang/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/karaf/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/karaf/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/karaf/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/kotlin/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/kotlin/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/kotlin/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/kscript/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/kscript/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/kscript/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/lazybones/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/lazybones/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/lazybones/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/leiningen/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/leiningen/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/leiningen/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/maven/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/maven/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/maven/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/micronaut/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/micronaut/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/micronaut/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/mulefd/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/mulefd/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/mulefd/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/mvnd/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/mvnd/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/mvnd/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/sbt/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/sbt/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/sbt/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/scala/current ]]\n",
            "++ __sdkman_export_candidate_home scala /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ local candidate_name=scala\n",
            "++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ echo scala\n",
            "+++ tr '[:lower:]' '[:upper:]'\n",
            "++ local candidate_home_var=SCALA_HOME\n",
            "+++ echo SCALA_HOME\n",
            "++ export SCALA_HOME=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ SCALA_HOME=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ __sdkman_prepend_candidate_to_path /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ local candidate_dir candidate_bin_dir\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ __sdkman_determine_candidate_bin_dir /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ local candidate_dir=/tmp/jovyan/.sdkman/candidates/scala/current\n",
            "+++ [[ -d /tmp/jovyan/.sdkman/candidates/scala/current/bin ]]\n",
            "+++ echo /tmp/jovyan/.sdkman/candidates/scala/current/bin\n",
            "++ candidate_bin_dir=/tmp/jovyan/.sdkman/candidates/scala/current/bin\n",
            "++ echo /tmp/jovyan/.sdkman/candidates/java/current/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ grep -q /tmp/jovyan/.sdkman/candidates/scala/current\n",
            "++ PATH=/tmp/jovyan/.sdkman/candidates/scala/current/bin:/tmp/jovyan/.sdkman/candidates/java/current/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/opt/gatk-4.1.9.0:/opt/vt:/opt/ensembl-vep\n",
            "++ unset CANDIDATE_BIN_DIR\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/spark/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/spark/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/spark/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/springboot/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/springboot/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/springboot/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/sshoogr/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/sshoogr/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/sshoogr/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/test/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/test/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/test/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/tomcat/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/tomcat/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/tomcat/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/vertx/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/vertx/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/vertx/current ]]\n",
            "++ for candidate_name in \"${SDKMAN_CANDIDATES[@]}\"\n",
            "++ candidate_dir=/tmp/jovyan/.sdkman/candidates/visualvm/current\n",
            "++ [[ -h /tmp/jovyan/.sdkman/candidates/visualvm/current ]]\n",
            "++ [[ -d /tmp/jovyan/.sdkman/candidates/visualvm/current ]]\n",
            "++ unset candidate_name candidate_dir\n",
            "++ export PATH\n",
            "++ [[ false == \\t\\r\\u\\e ]]\n",
            "+ echo ls /tmp/dummy\n",
            "ls /tmp/dummy\n",
            "+ BIODATAGEEKS_REPOS=https://oss.sonatype.org/content/repositories/snapshots/\n",
            "/usr/local/bin/entrypoint.sh: line 11: DS_LAB_GCS_KEY: GCS key is missing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "!ngrok config add-authtoken \"2o1oleMV7o19pWSV92909mOVXNI_3GnoVyejLABkMweQQTk6G\"\n",
        "\n",
        "# Open a tunnel to the Jupyter Notebook port\n",
        "public_url = ngrok.connect(8888)\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "id": "MjaHvWgFwv6V",
        "outputId": "ab6bfa1f-4d67-492d-ed6f-42908257ddc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "NgrokTunnel: \"https://7bd5-35-233-218-180.ngrok-free.app\" -> \"http://localhost:8888\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxaO2kBresWl"
      },
      "source": [
        "W przepływie pracy WDL zadania wykonywane są zgodnie z ich zależnościami:\n",
        "\n",
        "* Zadania mogą działać równolegle, jeśli nie zależą od siebie nawzajem.\n",
        "* Jeśli zadanie wymaga danych wyjściowych z innego zadania jako danych wejściowych, będzie czekać na zakończenie tego zależnego zadania.\n",
        "\n",
        "Ten łańcuch zależności pozwala WDL automatycznie zarządzać transferami plików, planowaniem i monitorowaniem zadań.\n",
        "\n",
        "***\n",
        "### Uruchamianie potoku do uliniowienia plików FASTQ i konwersji wynikowego pliku SAM do formatu BAM\n",
        "Uruchomienie potoku wymaga w tym przypadku podania również lokalizacji pliku ze ścieżkami do plików wejściowych za pomocą opcji `-i`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GQu2eoyesWl"
      },
      "outputs": [],
      "source": [
        "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
        "run dags/alignment.wdl -i dags/alignment-inputs.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74YW14HFesWl"
      },
      "source": [
        "Przyjrzyjmy się plikom w folderach wynikowych `cromwell-executions`. Każdy z uruchamianych skryptów WDL tworzy folder o nazwie takie samej jak w nagłówku:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epx3uGAnesWl"
      },
      "outputs": [],
      "source": [
        "# Wyciągnięcie informacji o nazwie potoku\n",
        "! sed -n '3,3p' dags/alignment.wdl\n",
        "# Listowanie zawartości folderu\n",
        "! ls cromwell-executions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gYp5JMmesWl"
      },
      "source": [
        "Kolejny folder ma nazwę nadawaną losowo, natomiast w  nim znajdziemy foldery z nazwami związanymi z poszczególnymi etapami określonymi w skrypcie WDL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95mpzsLVesWl"
      },
      "outputs": [],
      "source": [
        "# Wyciągnięcie informacji o nazwach zadań\n",
        "! sed -n '17,18p;29,30p' dags/alignment.wdl\n",
        "# Listowanie zawartości folderu\n",
        "! ls -d cromwell-executions/alignment_pipeline/*/call-*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI2Y3vlCesWl"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Zadanie 7_2:</b> Przyjrzyj się plikom w folderach <b>inputs</b> oraz <b>execution</b>. Jakie rodzaje plików w nich znajdziemy?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzOOMTp7esWl"
      },
      "source": [
        "W przypadku pierwszego kroku `BwaMem` pliki wejściowe pobierane są zgodnie z plikiem `alignment-inputs.json`, natomiast plik wejściowy dla kolejnego etapu `SamToBam` stanowi plik wynikowy z kroku wcześniejszego:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnWdTo1GesWl"
      },
      "outputs": [],
      "source": [
        "! sed -n '29,32p;59,62p' dags/alignment.wdl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9vy45ETesWl"
      },
      "source": [
        "Dzięki przekazywaniu plików wynikowych z jednego etapu jako plików wejściowych następnego etapu tworzymy podstawowy potok w którym dane przepływają oraz analizowane są w zdefiniowany sposób.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://docs.openwdl.org/en/latest/Images/linear_chaining.png\"\n",
        "width=400/>\n",
        "</div>\n",
        "\n",
        "[Przykłady łączenia etapów w sekwencji](https://docs.openwdl.org/en/latest/WDL/Linear_chaining/)\n",
        "\n",
        "Jednak nasz potok danych jest niepełny, brakuje w nim kilku etapów chociażby wykrywania wariantów.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Zadanie 7_3:</b> Dodaj krok wykrywania wariantów z użyciem narzędzia GATK HaplotypeCaller, który nazwij <b>GatkHc</b> gdzie plikami wejściowymi będą plik BAM z etapu SamToBam oraz plik FASTA genomu referencyjnego. Zapisz nowy potok pod nazwą <b>dags/alignment-vc.wdl</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB3U1OFdesWl"
      },
      "outputs": [],
      "source": [
        "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
        "run dags/alignment-vc.wdl -i dags/alignment-inputs.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwQEbyqjesWl"
      },
      "source": [
        "Dodawanie kolejnych kroków wymaga dobrego rozeznania w poszczególnych etapach całego potoku oraz ścisłego ustalenia poszczególnych plików wejściowych i ustawień programu. Jednak obsługa dynamicznych konstrukcję ścieżek i osadzanie parametrów za pomocą wyrażeń takich jak  `~{}` ułatwia obsługę zmiennych nazw plików, katalogów pośrednich i sparametryzowanych poleceń.\n",
        "\n",
        "***\n",
        "### Analiza wielu plików jednocześnie\n",
        "\n",
        "Jednak rozszerzanie potoku o dodatkowe kroki to połowa sukcesu. Niezwykle ważna w kontekście wydajności potoku jest możliwość jednoczesnej analizy wielu plików wejściowych jednocześnie. Do tego celu używany jest `scatter` czyli funkcjonalność WDL służąca do zrównoleglania potoku (lub niektórych jego części) przez iterację nad każdym elementem w tablicy (`Array`). Tworzy oddzielną instancję zadania dla każdego elementu tablicy, uruchamiając zadania dla każdego elementu niezależnie i jednocześnie, jeśli pozwalają na to zasoby obliczeniowe.\n",
        "\n",
        "Aby wykorzystać `scatter` należy stworzyć tablicę (`Array`), która w WDL stanowi kolekcję elementów tego samego typu. Tablice umożliwiają potokom obsługę wielu danych wejściowych dla podobnego zadania, umożliwiając przekazywanie listy plików, ciągów znaków, liczb całkowitych lub innych typów danych.\n",
        "\n",
        "[Przykłady wykorzystania funkcjonalności scatter](https://docs.openwdl.org/en/latest/WDL/scattering_index/)\n",
        "\n",
        "W celu lepszego zrozumienia rodzaju danych wejściowych zerknijmy na plik ze ścieżkami `dags/alignment-inputs-trio.json`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9VJUmlbesWm"
      },
      "outputs": [],
      "source": [
        "! sed -n '8,19p' dags/alignment-inputs-trio.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6avufcfesWm"
      },
      "source": [
        "Ścieżki do plików FASTQ poszczególnych członków rodziny zostały zagnieżdżone w zmiennej `fastq_files`, podobna lista została również utworzona dla zmiennej `sample_names` i zawiera nazwy poszczególnych członków rodziny. Stwarza to możliwość iterowania po tych listach, czyli wybierania elementów listy według ich indeksów i wykonywanie na nich kolejnych etapów analizy.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Zadanie 7_4:</b> Zmodyfikuj skrypt <b>dags/alignment-vc.wdl</b> w taki sposób, aby umożliwiał równoległe procesowanie wszystkich próbek w rodzinie (mother, father, son) na poszczególnych etapach potoku. Użyj opcji <b>Array</b> dla plików wejściowych oraz polecenia <b>scatter()</b> dla zrównoleglenia wykonywanych czynności. Zapisz skrypt pod nazwą <b>dags/alignment-vc-trio.wdl</b>. Użyj zmodyfikowanego pliku ze ścieżkami do plików wejściowych <b>dags/alignment-inputs-trio.json</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPpfnTn8esWm"
      },
      "outputs": [],
      "source": [
        "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
        "run dags/alignment-vc-trio.wdl -i dags/alignment-inputs-trio.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFiAlxUFesWm"
      },
      "source": [
        "### Rozgałęzianie oraz scalanie etapów potoku\n",
        "<div>\n",
        "<img src=\"https://docs.openwdl.org/en/latest/Images/branch_merge.png\"\n",
        "width=400/>\n",
        "</div>\n",
        "\n",
        "Do tej pory wykorzystywaliśmy prosty schemat wykonywania operacji jedna po drugiej. Natomiast często niektóre elementy potoku będą wykonywane na innych zbiorach plików lub będą korzystały z plików wynikowych z różnych etapów. Przykładem może być analiza jakościowa wykonywana za pomocą `MultiQC` które wykorzystuje wyniki z różnych narzędzi uruchamianych na poszczególnych etapach potoku.\n",
        "\n",
        "[Przykłady rozgałęziania i scalania etapów](https://docs.openwdl.org/en/latest/WDL/Branch_and_merge/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcm4jIJTesWm"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Zadanie 7_5:</b> Zmodyfikuj skrypt <b>dags/alignment-vc.wdl</b> poprzez dodanie etapów analizy <b>FastQC</b> na plikach FASTQ, <b>samtools flagstat</b> na plikach BAM oraz <b>bcftools stats</b> na plikach VCF. Na końcu dodaj krok analizy danych wynikowych z tych programów z użyciem <b>MultiQC</b>. Zapisz skrypt pod nazwą <b>dags/alignment-vc-trio-qc.wdl</b>.\n",
        "</div>\n",
        "\n",
        "Dla programu FastQC ustal wersję Javy którą ma używać za pomoca opcji: \\\n",
        "`-j /usr/lib/jvm/java-11-openjdk-amd64/bin/java`.\n",
        "\n",
        "Wcześniej zainstalowaliśmy brakujące MultiQC przed którego wywołaniem trzeba użyć komendy: \\\n",
        "`export XDG_CONFIG_HOME=work/git/edugen-notebooks/20Z/dags`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aubDo-NtesWm"
      },
      "outputs": [],
      "source": [
        "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
        "run dags/alignment-vc-trio-qc.wdl -i dags/alignment-inputs-trio.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYWApgKPesWm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "edugen",
      "language": "python",
      "name": "edugen"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}